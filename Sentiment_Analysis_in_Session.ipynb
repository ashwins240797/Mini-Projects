{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=green>Sentiment Analysis</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=orange>Click bellow for redirecting to repsective pages</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Exploring the dataset](#Exploring-the-dataset)\n",
    "\n",
    "   \n",
    "2. [Conversion of text to Cross Sectional Data](#Conversion-of-text-to-Cross-Sectional-Data)\n",
    "\n",
    "\n",
    "3. [Naive Bayes Model](#Naive-Bayes-Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data \n",
    "\n",
    "##### 1 is positive Review and 0 is Negative Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "train_ds = pd.read_csv( \"data_for_sentiment_analysis\", delimiter=\"\\t\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Da Vinci Code book is just awesome.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>this was the first clive cussler i've ever rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>i liked the Da Vinci Code a lot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>i liked the Da Vinci Code a lot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>I liked the Da Vinci Code but it ultimatly did...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          1            The Da Vinci Code book is just awesome.\n",
       "1          1  this was the first clive cussler i've ever rea...\n",
       "2          1                   i liked the Da Vinci Code a lot.\n",
       "3          1                   i liked the Da Vinci Code a lot.\n",
       "4          1  I liked the Da Vinci Code but it ultimatly did..."
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Da Vinci Code book is just awesome.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>this was the first clive cussler i've ever rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>i liked the Da Vinci Code a lot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>i liked the Da Vinci Code a lot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>I liked the Da Vinci Code but it ultimatly did...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          1            The Da Vinci Code book is just awesome.\n",
       "1          1  this was the first clive cussler i've ever rea...\n",
       "2          1                   i liked the Da Vinci Code a lot.\n",
       "3          1                   i liked the Da Vinci Code a lot.\n",
       "4          1  I liked the Da Vinci Code but it ultimatly did..."
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[train_ds.sentiment == 1][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3943</th>\n",
       "      <td>0</td>\n",
       "      <td>da vinci code was a terrible movie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3944</th>\n",
       "      <td>0</td>\n",
       "      <td>Then again, the Da Vinci code is super shitty ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3945</th>\n",
       "      <td>0</td>\n",
       "      <td>The Da Vinci Code comes out tomorrow, which su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3946</th>\n",
       "      <td>0</td>\n",
       "      <td>i thought the da vinci code movie was really b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3947</th>\n",
       "      <td>0</td>\n",
       "      <td>God, Yahoo Games has this truly-awful looking ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                               text\n",
       "3943          0                da vinci code was a terrible movie.\n",
       "3944          0  Then again, the Da Vinci code is super shitty ...\n",
       "3945          0  The Da Vinci Code comes out tomorrow, which su...\n",
       "3946          0  i thought the da vinci code movie was really b...\n",
       "3947          0  God, Yahoo Games has this truly-awful looking ..."
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[train_ds.sentiment == 0][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6918 entries, 0 to 6917\n",
      "Data columns (total 2 columns):\n",
      "sentiment    6918 non-null int64\n",
      "text         6918 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 108.2+ KB\n"
     ]
    }
   ],
   "source": [
    "train_ds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x360 with 0 Axes>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "%matplotlib inline\n",
    "plt.figure( figsize=(6,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create count plot\n",
    "ax = sn.countplot(x='sentiment', data=train_ds)\n",
    "# annotate\n",
    "for p in ax.patches:\n",
    "    ax.annotate(p.get_height(), (p.get_x()+0.1, p.get_height()+50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_volume = train_ds[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.00375831165076"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(review_volume[0]/train_ds.shape[0])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.99624168834924"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(review_volume[1]/train_ds.shape[0])*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference : The no. of data points for both the catagres are balanced and hence it is good to proceed with Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion of text to Cross Sectional Data\n",
    "\n",
    "* Count Vector Model (Bag Of Word)\n",
    "* Term Frequency model\n",
    "* Term Frequency - Inverse Document Frequency (TF-IDF) model\n",
    "* Ngram(s) model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vector Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# Create the dictionary from the corpus\n",
    "feature_vector = count_vectorizer.fit( train_ds.text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of features:  2132\n"
     ]
    }
   ],
   "source": [
    "# Get the feature names\n",
    "features = feature_vector.get_feature_names()\n",
    "print( \"Total number of features: \", len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['could',\n",
       " 'romantic',\n",
       " 'point',\n",
       " 'anywhere',\n",
       " 'generally',\n",
       " 'altogether',\n",
       " 'suppose',\n",
       " 'grand',\n",
       " 'avatar',\n",
       " 'tomorrow']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.sample(features, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds_features = count_vectorizer.transform( train_ds.text )\n",
    "type(train_ds_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6918x2132 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 65398 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying Document Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the matrix to a dataframe\n",
    "train_ds_df = pd.DataFrame(train_ds_features.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the column names to the features i.e. words\n",
    "train_ds_df.columns = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>007</th>\n",
       "      <th>10</th>\n",
       "      <th>10pm</th>\n",
       "      <th>12</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>1984</th>\n",
       "      <th>1st</th>\n",
       "      <th>200</th>\n",
       "      <th>...</th>\n",
       "      <th>yip</th>\n",
       "      <th>you</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>your</th>\n",
       "      <th>yuck</th>\n",
       "      <th>yuh</th>\n",
       "      <th>zach</th>\n",
       "      <th>zen</th>\n",
       "      <th>µª</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  007  10  10pm  12  16  17  1984  1st  200  ...  yip  you  young  \\\n",
       "0   0    0   0     0   0   0   0     0    0    0  ...    0    0      0   \n",
       "1   0    0   0     0   0   0   0     0    0    0  ...    0    0      0   \n",
       "2   0    0   0     0   0   0   0     0    0    0  ...    0    0      0   \n",
       "3   0    0   0     0   0   0   0     0    0    0  ...    0    0      0   \n",
       "4   0    0   0     0   0   0   0     0    0    0  ...    0    0      0   \n",
       "\n",
       "   younger  your  yuck  yuh  zach  zen  µª  \n",
       "0        0     0     0    0     0    0   0  \n",
       "1        0     0     0    0     0    0   0  \n",
       "2        0     0     0    0     0    0   0  \n",
       "3        0     0     0    0     0    0   0  \n",
       "4        0     0     0    0     0    0   0  \n",
       "\n",
       "[5 rows x 2132 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Da Vinci Code book is just awesome.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                     text\n",
       "0          1  The Da Vinci Code book is just awesome."
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>away</th>\n",
       "      <th>awesome</th>\n",
       "      <th>awesomely</th>\n",
       "      <th>awesomeness</th>\n",
       "      <th>awesomest</th>\n",
       "      <th>awful</th>\n",
       "      <th>awkward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   away  awesome  awesomely  awesomeness  awesomest  awful  awkward\n",
       "0     0        1          0            0          0      0        0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds_df.iloc[0:1, 150:157]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing low frequency words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  4, ...,  1, 80,  1], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summing up the occurances of features column wise\n",
    "features_counts = np.sum( train_ds_features.toarray(), axis = 0 )\n",
    "features_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_counts_df = pd.DataFrame( dict( features = features,\n",
    "counts = features_counts ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10pm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>yuck</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>yuh</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>zach</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130</th>\n",
       "      <td>zen</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>µª</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2132 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     features  counts\n",
       "0          00       1\n",
       "1         007       1\n",
       "2          10       4\n",
       "3        10pm       1\n",
       "4          12       1\n",
       "...       ...     ...\n",
       "2127     yuck       1\n",
       "2128      yuh       1\n",
       "2129     zach       1\n",
       "2130      zen      80\n",
       "2131       µª       1\n",
       "\n",
       "[2132 rows x 2 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure( figsize=(12,5))\n",
    "plt.hist(feature_counts_df.counts, bins=50, range = (0, 2000));\n",
    "plt.xlabel( 'Frequency of words' )\n",
    "plt.ylabel( 'Density' );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the CountVectorizer\n",
    "count_vectorizer = CountVectorizer(max_features=1000)\n",
    "# Create the dictionary from the corpus\n",
    "feature_vector = count_vectorizer.fit( train_ds.text )\n",
    "# Get the feature names\n",
    "features = feature_vector.get_feature_names()\n",
    "# Transform the document into vectors\n",
    "train_ds_features = count_vectorizer.transform( train_ds.text )\n",
    "# Count the frequency of the features\n",
    "features_counts = np.sum( train_ds_features.toarray(), axis = 0 )\n",
    "feature_counts = pd.DataFrame( dict( features = features,\n",
    "counts = features_counts ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6th</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aaron</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>yesterday</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>yet</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>you</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>your</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>zen</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      features  counts\n",
       "0           10       4\n",
       "1           17       3\n",
       "2           33       2\n",
       "3          6th       3\n",
       "4        aaron       2\n",
       "..         ...     ...\n",
       "995  yesterday       2\n",
       "996        yet       8\n",
       "997        you     331\n",
       "998       your       9\n",
       "999        zen      80\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Stop Words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "my_stop_words = text.ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding custom words to the list of stop words\n",
    "my_stop_words = text.ENGLISH_STOP_WORDS.union( ['harry', 'potter', 'code', 'vinci', 'da','harry', 'mountain', 'movie', 'movies'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Count Vectors with removal of Stop Words and Considering highly frequent words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer( stop_words = my_stop_words,max_features = 1000 )\n",
    "feature_vector = count_vectorizer.fit( train_ds.text )\n",
    "train_ds_features = count_vectorizer.transform( train_ds.text )\n",
    "features = feature_vector.get_feature_names()\n",
    "features_counts = np.sum( train_ds_features.toarray(), axis = 0 )\n",
    "feature_counts = pd.DataFrame( dict( features = features,counts = features_counts ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>brokeback</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>love</td>\n",
       "      <td>1624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>awesome</td>\n",
       "      <td>1127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>mission</td>\n",
       "      <td>1094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>impossible</td>\n",
       "      <td>1093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>like</td>\n",
       "      <td>974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>sucks</td>\n",
       "      <td>602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>sucked</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>hate</td>\n",
       "      <td>578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>really</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>stupid</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>just</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>know</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>suck</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>loved</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       features  counts\n",
       "73    brokeback    2000\n",
       "408        love    1624\n",
       "39      awesome    1127\n",
       "436     mission    1094\n",
       "341  impossible    1093\n",
       "390        like     974\n",
       "745       sucks     602\n",
       "743      sucked     600\n",
       "297        hate     578\n",
       "652      really     374\n",
       "741      stupid     365\n",
       "362        just     287\n",
       "374        know     276\n",
       "742        suck     276\n",
       "409       loved     256"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_counts.sort_values( \"counts\", ascending = False )[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "analyzer = CountVectorizer().build_analyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmed_words(doc):\n",
    "    ### Stemming of words\n",
    "    stemmed_words = (stemmer.stem(w) for w in analyzer(doc))\n",
    "    ### Remove the words in stop words list\n",
    "    non_stop_words = [ word for word in list(set(stemmed_words) - set(my_stop_words)) ]\n",
    "    return non_stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features with Stemmed Words and filtered by Stop Words which are highly frequent word  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>brokeback</td>\n",
       "      <td>1930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>harri</td>\n",
       "      <td>1916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>love</td>\n",
       "      <td>1837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>suck</td>\n",
       "      <td>1378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>wa</td>\n",
       "      <td>1142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>awesom</td>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>imposs</td>\n",
       "      <td>1090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>mission</td>\n",
       "      <td>1090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>movi</td>\n",
       "      <td>1052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>like</td>\n",
       "      <td>823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>hate</td>\n",
       "      <td>636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>becaus</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>realli</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>stupid</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>know</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      features  counts\n",
       "80   brokeback    1930\n",
       "297      harri    1916\n",
       "407       love    1837\n",
       "803       suck    1378\n",
       "922         wa    1142\n",
       "43      awesom    1116\n",
       "345     imposs    1090\n",
       "433    mission    1090\n",
       "439       movi    1052\n",
       "393       like     823\n",
       "299       hate     636\n",
       "54      becaus     524\n",
       "604     realli     370\n",
       "796     stupid     364\n",
       "379       know     354"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer( analyzer=stemmed_words, max_features = 1000)\n",
    "feature_vector = count_vectorizer.fit( train_ds.text )\n",
    "train_ds_features = count_vectorizer.transform( train_ds.text )\n",
    "features = feature_vector.get_feature_names()\n",
    "features_counts = np.sum( train_ds_features.toarray(), axis = 0 )\n",
    "feature_counts = pd.DataFrame( dict( features = features,\n",
    "counts = features_counts ) )\n",
    "feature_counts.sort_values( \"counts\", ascending = False )[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the document vector matrix into dataframe\n",
    "train_ds_df = pd.DataFrame(train_ds_features.todense())\n",
    "# Assign the features names to the column\n",
    "train_ds_df.columns = features\n",
    "# Assign the sentiment labels to the train_ds\n",
    "train_ds_df['sentiment'] = train_ds.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_y, test_y = train_test_split( train_ds_features,train_ds.sentiment,test_size = 0.3,random_state = 42 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       873\n",
      "           1       0.98      0.99      0.98      1203\n",
      "\n",
      "    accuracy                           0.98      2076\n",
      "   macro avg       0.98      0.98      0.98      2076\n",
      "weighted avg       0.98      0.98      0.98      2076\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "nb_clf = BernoulliNB()\n",
    "nb_clf.fit( train_X.toarray(), train_y )\n",
    "\n",
    "test_ds_predicted = nb_clf.predict( test_X.toarray() )\n",
    "\n",
    "from sklearn import metrics\n",
    "print( metrics.classification_report( test_y, test_ds_predicted ) )\n",
    "\n",
    "from sklearn import metrics\n",
    "cm = metrics.confusion_matrix( test_y, test_ds_predicted )\n",
    "sn.heatmap(cm, annot=True, fmt='.2f' );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_NAMES = [\"Process\",\"Model Name\", \"F1 Scores\",\"Range of F1 Scores\",\"Std Deviation of F1 Scores\"]\n",
    "df_model_selection = pd.DataFrame(columns=COLUMN_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Process</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>F1 Scores</th>\n",
       "      <th>Range of F1 Scores</th>\n",
       "      <th>Std Deviation of F1 Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Process, Model Name, F1 Scores, Range of F1 Scores, Std Deviation of F1 Scores]\n",
       "Index: []"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_K_fold_validation(model_obj, model_name, process, n_splits, X, y):\n",
    "    global df_model_selection\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits, random_state=29)\n",
    "    \n",
    "    weighted_f1_score = []\n",
    "    print(skf.split(X,y))\n",
    "    for train_index, val_index in skf.split(X,y):\n",
    "        X_train, X_test = X[train_index], X[val_index] \n",
    "        y_train, y_test = y[train_index], y[val_index]\n",
    "        \n",
    "        \n",
    "        model_obj.fit(X_train, y_train)##### HERE ###\n",
    "        test_ds_predicted = model_obj.predict( X_test ) ##### HERE ####   \n",
    "        #print( metrics.classification_report( y_test, test_ds_predicted ) )    \n",
    "        weighted_f1_score.append(round(f1_score(y_test, test_ds_predicted , average='weighted'),2))\n",
    "        \n",
    "    sd_weighted_f1_score = np.std(weighted_f1_score, ddof=1)\n",
    "    range_of_f1_scores = \"{}-{}\".format(min(weighted_f1_score),max(weighted_f1_score))    \n",
    "    df_model_selection = pd.concat([df_model_selection,pd.DataFrame([[process,model_name,sorted(weighted_f1_score),range_of_f1_scores,sd_weighted_f1_score]], columns =COLUMN_NAMES) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "nb_clf = BernoulliNB()\n",
    "nb_clf.fit( train_X.toarray(), train_y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object _BaseKFold.split at 0x000002156B789948>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Process</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>F1 Scores</th>\n",
       "      <th>Range of F1 Scores</th>\n",
       "      <th>Std Deviation of F1 Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Binomial Naive Bayes Classifier</td>\n",
       "      <td>[0.92, 0.98, 0.99, 0.99, 1.0]</td>\n",
       "      <td>0.92-1.0</td>\n",
       "      <td>0.032094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Process                       Model Name  \\\n",
       "0  Bag Of Words with NLTK Stemming  Binomial Naive Bayes Classifier   \n",
       "\n",
       "                       F1 Scores Range of F1 Scores  \\\n",
       "0  [0.92, 0.98, 0.99, 0.99, 1.0]           0.92-1.0   \n",
       "\n",
       "   Std Deviation of F1 Scores  \n",
       "0                    0.032094  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_obj = nb_clf\n",
    "model_name = \"Binomial Naive Bayes Classifier\"\n",
    "process = \"Bag Of Words with NLTK Stemming\"\n",
    "n_splits = 5\n",
    "X = train_ds_features.toarray()\n",
    "y = train_ds.sentiment\n",
    "stratified_K_fold_validation(model_obj, model_name, process, n_splits, X, y)\n",
    "\n",
    "\n",
    "df_model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(train_X.toarray(), train_y)\n",
    "test_ds_predicted = logreg.predict( test_X.toarray() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       873\n",
      "           1       0.99      1.00      0.99      1203\n",
      "\n",
      "    accuracy                           0.99      2076\n",
      "   macro avg       0.99      0.99      0.99      2076\n",
      "weighted avg       0.99      0.99      0.99      2076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print( metrics.classification_report( test_y, test_ds_predicted ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object _BaseKFold.split at 0x00000215014EE1C8>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Process</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>F1 Scores</th>\n",
       "      <th>Range of F1 Scores</th>\n",
       "      <th>Std Deviation of F1 Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Binomial Naive Bayes Classifier</td>\n",
       "      <td>[0.92, 0.98, 0.99, 0.99, 1.0]</td>\n",
       "      <td>0.92-1.0</td>\n",
       "      <td>0.032094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>[0.95, 0.98, 0.99, 1.0, 1.0]</td>\n",
       "      <td>0.95-1.0</td>\n",
       "      <td>0.020736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Process                       Model Name  \\\n",
       "0  Bag Of Words with NLTK Stemming  Binomial Naive Bayes Classifier   \n",
       "0  Bag Of Words with NLTK Stemming              Logistic Regression   \n",
       "\n",
       "                       F1 Scores Range of F1 Scores  \\\n",
       "0  [0.92, 0.98, 0.99, 0.99, 1.0]           0.92-1.0   \n",
       "0   [0.95, 0.98, 0.99, 1.0, 1.0]           0.95-1.0   \n",
       "\n",
       "   Std Deviation of F1 Scores  \n",
       "0                    0.032094  \n",
       "0                    0.020736  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_obj = logreg\n",
    "model_name = \"Logistic Regression\"\n",
    "process = \"Bag Of Words with NLTK Stemming\"\n",
    "n_splits = 5\n",
    "X = train_ds_features.toarray()\n",
    "y = train_ds.sentiment\n",
    "stratified_K_fold_validation(model_obj, model_name, process, n_splits, X, y)\n",
    "df_model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree = DecisionTreeClassifier(criterion='entropy')\n",
    "\n",
    "decision_tree.fit(train_X.toarray(), train_y)\n",
    "test_ds_predicted = decision_tree.predict( test_X.toarray() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       873\n",
      "           1       0.99      0.99      0.99      1203\n",
      "\n",
      "    accuracy                           0.99      2076\n",
      "   macro avg       0.99      0.99      0.99      2076\n",
      "weighted avg       0.99      0.99      0.99      2076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print( metrics.classification_report( test_y, test_ds_predicted ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object _BaseKFold.split at 0x00000215013E4CC8>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Process</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>F1 Scores</th>\n",
       "      <th>Range of F1 Scores</th>\n",
       "      <th>Std Deviation of F1 Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Binomial Naive Bayes Classifier</td>\n",
       "      <td>[0.92, 0.98, 0.99, 0.99, 1.0]</td>\n",
       "      <td>0.92-1.0</td>\n",
       "      <td>0.032094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>[0.95, 0.98, 0.99, 1.0, 1.0]</td>\n",
       "      <td>0.95-1.0</td>\n",
       "      <td>0.020736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Decission Tree</td>\n",
       "      <td>[0.92, 0.98, 0.99, 0.99, 1.0]</td>\n",
       "      <td>0.92-1.0</td>\n",
       "      <td>0.032094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Process                       Model Name  \\\n",
       "0  Bag Of Words with NLTK Stemming  Binomial Naive Bayes Classifier   \n",
       "0  Bag Of Words with NLTK Stemming              Logistic Regression   \n",
       "0  Bag Of Words with NLTK Stemming                   Decission Tree   \n",
       "\n",
       "                       F1 Scores Range of F1 Scores  \\\n",
       "0  [0.92, 0.98, 0.99, 0.99, 1.0]           0.92-1.0   \n",
       "0   [0.95, 0.98, 0.99, 1.0, 1.0]           0.95-1.0   \n",
       "0  [0.92, 0.98, 0.99, 0.99, 1.0]           0.92-1.0   \n",
       "\n",
       "   Std Deviation of F1 Scores  \n",
       "0                    0.032094  \n",
       "0                    0.020736  \n",
       "0                    0.032094  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_obj = decision_tree\n",
    "model_name = \"Decission Tree\"\n",
    "process = \"Bag Of Words with NLTK Stemming\"\n",
    "n_splits = 5\n",
    "X = train_ds_features.toarray()\n",
    "y = train_ds.sentiment\n",
    "stratified_K_fold_validation(model_obj, model_name, process, n_splits, X, y)\n",
    "df_model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_forest = RandomForestClassifier(n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest.fit(train_X.toarray(), train_y)\n",
    "test_ds_predicted = random_forest.predict( test_X.toarray() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       873\n",
      "           1       0.99      0.99      0.99      1203\n",
      "\n",
      "    accuracy                           0.99      2076\n",
      "   macro avg       0.99      0.99      0.99      2076\n",
      "weighted avg       0.99      0.99      0.99      2076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print( metrics.classification_report( test_y, test_ds_predicted ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object _BaseKFold.split at 0x000002150145F5C8>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Process</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>F1 Scores</th>\n",
       "      <th>Range of F1 Scores</th>\n",
       "      <th>Std Deviation of F1 Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Binomial Naive Bayes Classifier</td>\n",
       "      <td>[0.92, 0.98, 0.99, 0.99, 1.0]</td>\n",
       "      <td>0.92-1.0</td>\n",
       "      <td>0.032094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>[0.95, 0.98, 0.99, 1.0, 1.0]</td>\n",
       "      <td>0.95-1.0</td>\n",
       "      <td>0.020736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Decission Tree</td>\n",
       "      <td>[0.92, 0.98, 0.99, 0.99, 1.0]</td>\n",
       "      <td>0.92-1.0</td>\n",
       "      <td>0.032094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>[0.92, 0.96, 0.99, 0.99, 1.0]</td>\n",
       "      <td>0.92-1.0</td>\n",
       "      <td>0.032711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Process                       Model Name  \\\n",
       "0  Bag Of Words with NLTK Stemming  Binomial Naive Bayes Classifier   \n",
       "0  Bag Of Words with NLTK Stemming              Logistic Regression   \n",
       "0  Bag Of Words with NLTK Stemming                   Decission Tree   \n",
       "0  Bag Of Words with NLTK Stemming                    Random Forest   \n",
       "\n",
       "                       F1 Scores Range of F1 Scores  \\\n",
       "0  [0.92, 0.98, 0.99, 0.99, 1.0]           0.92-1.0   \n",
       "0   [0.95, 0.98, 0.99, 1.0, 1.0]           0.95-1.0   \n",
       "0  [0.92, 0.98, 0.99, 0.99, 1.0]           0.92-1.0   \n",
       "0  [0.92, 0.96, 0.99, 0.99, 1.0]           0.92-1.0   \n",
       "\n",
       "   Std Deviation of F1 Scores  \n",
       "0                    0.032094  \n",
       "0                    0.020736  \n",
       "0                    0.032094  \n",
       "0                    0.032711  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_obj = random_forest\n",
    "model_name = \"Random Forest\"\n",
    "process = \"Bag Of Words with NLTK Stemming\"\n",
    "n_splits = 5\n",
    "X = train_ds_features.toarray()\n",
    "y = train_ds.sentiment\n",
    "stratified_K_fold_validation(model_obj, model_name, process, n_splits, X, y)\n",
    "df_model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgboost = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost.fit(train_X.toarray(), train_y)\n",
    "test_ds_predicted = xgboost.predict( test_X.toarray() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       873\n",
      "           1       0.99      0.99      0.99      1203\n",
      "\n",
      "    accuracy                           0.99      2076\n",
      "   macro avg       0.99      0.99      0.99      2076\n",
      "weighted avg       0.99      0.99      0.99      2076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print( metrics.classification_report( test_y, test_ds_predicted ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object _BaseKFold.split at 0x00000215021E77C8>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Process</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>F1 Scores</th>\n",
       "      <th>Range of F1 Scores</th>\n",
       "      <th>Std Deviation of F1 Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Binomial Naive Bayes Classifier</td>\n",
       "      <td>[0.92, 0.98, 0.99, 0.99, 1.0]</td>\n",
       "      <td>0.92-1.0</td>\n",
       "      <td>0.032094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>[0.95, 0.98, 0.99, 1.0, 1.0]</td>\n",
       "      <td>0.95-1.0</td>\n",
       "      <td>0.020736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Decission Tree</td>\n",
       "      <td>[0.92, 0.98, 0.99, 0.99, 1.0]</td>\n",
       "      <td>0.92-1.0</td>\n",
       "      <td>0.032094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>[0.92, 0.96, 0.99, 0.99, 1.0]</td>\n",
       "      <td>0.92-1.0</td>\n",
       "      <td>0.032711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>XG Boost</td>\n",
       "      <td>[0.95, 0.97, 0.99, 0.99, 1.0]</td>\n",
       "      <td>0.95-1.0</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Process                       Model Name  \\\n",
       "0  Bag Of Words with NLTK Stemming  Binomial Naive Bayes Classifier   \n",
       "0  Bag Of Words with NLTK Stemming              Logistic Regression   \n",
       "0  Bag Of Words with NLTK Stemming                   Decission Tree   \n",
       "0  Bag Of Words with NLTK Stemming                    Random Forest   \n",
       "0  Bag Of Words with NLTK Stemming                         XG Boost   \n",
       "\n",
       "                       F1 Scores Range of F1 Scores  \\\n",
       "0  [0.92, 0.98, 0.99, 0.99, 1.0]           0.92-1.0   \n",
       "0   [0.95, 0.98, 0.99, 1.0, 1.0]           0.95-1.0   \n",
       "0  [0.92, 0.98, 0.99, 0.99, 1.0]           0.92-1.0   \n",
       "0  [0.92, 0.96, 0.99, 0.99, 1.0]           0.92-1.0   \n",
       "0  [0.95, 0.97, 0.99, 0.99, 1.0]           0.95-1.0   \n",
       "\n",
       "   Std Deviation of F1 Scores  \n",
       "0                    0.032094  \n",
       "0                    0.020736  \n",
       "0                    0.032094  \n",
       "0                    0.032711  \n",
       "0                    0.020000  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_obj = xgboost\n",
    "model_name = \"XG Boost\"\n",
    "process = \"Bag Of Words with NLTK Stemming\"\n",
    "n_splits = 5\n",
    "X = train_ds_features.toarray()\n",
    "y = train_ds.sentiment\n",
    "stratified_K_fold_validation(model_obj, model_name, process, n_splits, X, y)\n",
    "df_model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "sgd = OneVsRestClassifier(SGDClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd.fit(train_X.toarray(), train_y)\n",
    "test_ds_predicted = sgd.predict( test_X.toarray() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       873\n",
      "           1       0.98      1.00      0.99      1203\n",
      "\n",
      "    accuracy                           0.99      2076\n",
      "   macro avg       0.99      0.99      0.99      2076\n",
      "weighted avg       0.99      0.99      0.99      2076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print( metrics.classification_report( test_y, test_ds_predicted ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object _BaseKFold.split at 0x00000215001FD4C8>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Process</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>F1 Scores</th>\n",
       "      <th>Range of F1 Scores</th>\n",
       "      <th>Std Deviation of F1 Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Binomial Naive Bayes Classifier</td>\n",
       "      <td>[0.92, 0.98, 0.99, 0.99, 1.0]</td>\n",
       "      <td>0.92-1.0</td>\n",
       "      <td>0.032094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>[0.95, 0.98, 0.99, 1.0, 1.0]</td>\n",
       "      <td>0.95-1.0</td>\n",
       "      <td>0.020736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Decission Tree</td>\n",
       "      <td>[0.92, 0.98, 0.99, 0.99, 1.0]</td>\n",
       "      <td>0.92-1.0</td>\n",
       "      <td>0.032094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>[0.92, 0.96, 0.99, 0.99, 1.0]</td>\n",
       "      <td>0.92-1.0</td>\n",
       "      <td>0.032711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>XG Boost</td>\n",
       "      <td>[0.95, 0.97, 0.99, 0.99, 1.0]</td>\n",
       "      <td>0.95-1.0</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Stochastic Gradient Descent</td>\n",
       "      <td>[0.96, 0.98, 0.99, 1.0, 1.0]</td>\n",
       "      <td>0.96-1.0</td>\n",
       "      <td>0.016733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Process                       Model Name  \\\n",
       "0  Bag Of Words with NLTK Stemming  Binomial Naive Bayes Classifier   \n",
       "0  Bag Of Words with NLTK Stemming              Logistic Regression   \n",
       "0  Bag Of Words with NLTK Stemming                   Decission Tree   \n",
       "0  Bag Of Words with NLTK Stemming                    Random Forest   \n",
       "0  Bag Of Words with NLTK Stemming                         XG Boost   \n",
       "0  Bag Of Words with NLTK Stemming      Stochastic Gradient Descent   \n",
       "\n",
       "                       F1 Scores Range of F1 Scores  \\\n",
       "0  [0.92, 0.98, 0.99, 0.99, 1.0]           0.92-1.0   \n",
       "0   [0.95, 0.98, 0.99, 1.0, 1.0]           0.95-1.0   \n",
       "0  [0.92, 0.98, 0.99, 0.99, 1.0]           0.92-1.0   \n",
       "0  [0.92, 0.96, 0.99, 0.99, 1.0]           0.92-1.0   \n",
       "0  [0.95, 0.97, 0.99, 0.99, 1.0]           0.95-1.0   \n",
       "0   [0.96, 0.98, 0.99, 1.0, 1.0]           0.96-1.0   \n",
       "\n",
       "   Std Deviation of F1 Scores  \n",
       "0                    0.032094  \n",
       "0                    0.020736  \n",
       "0                    0.032094  \n",
       "0                    0.032711  \n",
       "0                    0.020000  \n",
       "0                    0.016733  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_obj = sgd\n",
    "model_name = \"Stochastic Gradient Descent\"\n",
    "process = \"Bag Of Words with NLTK Stemming\"\n",
    "n_splits = 5\n",
    "X = train_ds_features.toarray()\n",
    "y = train_ds.sentiment\n",
    "stratified_K_fold_validation(model_obj, model_name, process, n_splits, X, y)\n",
    "df_model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Process Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "gausian_process = GaussianProcessClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "gausian_process.fit(train_X.toarray(), train_y)\n",
    "test_ds_predicted = gausian_process.predict( test_X.toarray() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98       873\n",
      "           1       0.98      1.00      0.99      1203\n",
      "\n",
      "    accuracy                           0.99      2076\n",
      "   macro avg       0.99      0.98      0.99      2076\n",
      "weighted avg       0.99      0.99      0.99      2076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print( metrics.classification_report( test_y, test_ds_predicted ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object _BaseKFold.split at 0x000002150238A148>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Process</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>F1 Scores</th>\n",
       "      <th>Range of F1 Scores</th>\n",
       "      <th>Std Deviation of F1 Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Binomial Naive Bayes Classifier</td>\n",
       "      <td>[0.92, 0.98, 0.99, 0.99, 1.0]</td>\n",
       "      <td>0.92-1.0</td>\n",
       "      <td>0.032094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>[0.95, 0.98, 0.99, 1.0, 1.0]</td>\n",
       "      <td>0.95-1.0</td>\n",
       "      <td>0.020736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Decission Tree</td>\n",
       "      <td>[0.92, 0.98, 0.99, 0.99, 1.0]</td>\n",
       "      <td>0.92-1.0</td>\n",
       "      <td>0.032094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>[0.92, 0.96, 0.99, 0.99, 1.0]</td>\n",
       "      <td>0.92-1.0</td>\n",
       "      <td>0.032711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>XG Boost</td>\n",
       "      <td>[0.95, 0.97, 0.99, 0.99, 1.0]</td>\n",
       "      <td>0.95-1.0</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Stochastic Gradient Descent</td>\n",
       "      <td>[0.96, 0.98, 0.99, 1.0, 1.0]</td>\n",
       "      <td>0.96-1.0</td>\n",
       "      <td>0.016733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Gausian Process</td>\n",
       "      <td>[0.93, 0.99, 0.99, 0.99, 1.0]</td>\n",
       "      <td>0.93-1.0</td>\n",
       "      <td>0.028284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Process                       Model Name  \\\n",
       "0  Bag Of Words with NLTK Stemming  Binomial Naive Bayes Classifier   \n",
       "0  Bag Of Words with NLTK Stemming              Logistic Regression   \n",
       "0  Bag Of Words with NLTK Stemming                   Decission Tree   \n",
       "0  Bag Of Words with NLTK Stemming                    Random Forest   \n",
       "0  Bag Of Words with NLTK Stemming                         XG Boost   \n",
       "0  Bag Of Words with NLTK Stemming      Stochastic Gradient Descent   \n",
       "0  Bag Of Words with NLTK Stemming                  Gausian Process   \n",
       "\n",
       "                       F1 Scores Range of F1 Scores  \\\n",
       "0  [0.92, 0.98, 0.99, 0.99, 1.0]           0.92-1.0   \n",
       "0   [0.95, 0.98, 0.99, 1.0, 1.0]           0.95-1.0   \n",
       "0  [0.92, 0.98, 0.99, 0.99, 1.0]           0.92-1.0   \n",
       "0  [0.92, 0.96, 0.99, 0.99, 1.0]           0.92-1.0   \n",
       "0  [0.95, 0.97, 0.99, 0.99, 1.0]           0.95-1.0   \n",
       "0   [0.96, 0.98, 0.99, 1.0, 1.0]           0.96-1.0   \n",
       "0  [0.93, 0.99, 0.99, 0.99, 1.0]           0.93-1.0   \n",
       "\n",
       "   Std Deviation of F1 Scores  \n",
       "0                    0.032094  \n",
       "0                    0.020736  \n",
       "0                    0.032094  \n",
       "0                    0.032711  \n",
       "0                    0.020000  \n",
       "0                    0.016733  \n",
       "0                    0.028284  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_obj = gausian_process\n",
    "model_name = \"Gausian Process\"\n",
    "process = \"Bag Of Words with NLTK Stemming\"\n",
    "n_splits = 5\n",
    "X = train_ds_features.toarray()\n",
    "y = train_ds.sentiment\n",
    "stratified_K_fold_validation(model_obj, model_name, process, n_splits, X, y)\n",
    "df_model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(train_X.toarray(), train_y)\n",
    "test_ds_predicted = knn.predict( test_X.toarray() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       873\n",
      "           1       0.97      1.00      0.99      1203\n",
      "\n",
      "    accuracy                           0.98      2076\n",
      "   macro avg       0.99      0.98      0.98      2076\n",
      "weighted avg       0.98      0.98      0.98      2076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print( metrics.classification_report( test_y, test_ds_predicted ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object _BaseKFold.split at 0x000002150238AB48>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Process</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>F1 Scores</th>\n",
       "      <th>Range of F1 Scores</th>\n",
       "      <th>Std Deviation of F1 Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Binomial Naive Bayes Classifier</td>\n",
       "      <td>[0.92, 0.98, 0.99, 0.99, 1.0]</td>\n",
       "      <td>0.92-1.0</td>\n",
       "      <td>0.032094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>[0.95, 0.98, 0.99, 1.0, 1.0]</td>\n",
       "      <td>0.95-1.0</td>\n",
       "      <td>0.020736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Decission Tree</td>\n",
       "      <td>[0.92, 0.98, 0.99, 0.99, 1.0]</td>\n",
       "      <td>0.92-1.0</td>\n",
       "      <td>0.032094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>[0.92, 0.96, 0.99, 0.99, 1.0]</td>\n",
       "      <td>0.92-1.0</td>\n",
       "      <td>0.032711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>XG Boost</td>\n",
       "      <td>[0.95, 0.97, 0.99, 0.99, 1.0]</td>\n",
       "      <td>0.95-1.0</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Stochastic Gradient Descent</td>\n",
       "      <td>[0.96, 0.98, 0.99, 1.0, 1.0]</td>\n",
       "      <td>0.96-1.0</td>\n",
       "      <td>0.016733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Gausian Process</td>\n",
       "      <td>[0.93, 0.99, 0.99, 0.99, 1.0]</td>\n",
       "      <td>0.93-1.0</td>\n",
       "      <td>0.028284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>K Nearst Neighbour</td>\n",
       "      <td>[0.92, 0.97, 0.98, 0.99, 1.0]</td>\n",
       "      <td>0.92-1.0</td>\n",
       "      <td>0.031145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Process                       Model Name  \\\n",
       "0  Bag Of Words with NLTK Stemming  Binomial Naive Bayes Classifier   \n",
       "0  Bag Of Words with NLTK Stemming              Logistic Regression   \n",
       "0  Bag Of Words with NLTK Stemming                   Decission Tree   \n",
       "0  Bag Of Words with NLTK Stemming                    Random Forest   \n",
       "0  Bag Of Words with NLTK Stemming                         XG Boost   \n",
       "0  Bag Of Words with NLTK Stemming      Stochastic Gradient Descent   \n",
       "0  Bag Of Words with NLTK Stemming                  Gausian Process   \n",
       "0  Bag Of Words with NLTK Stemming               K Nearst Neighbour   \n",
       "\n",
       "                       F1 Scores Range of F1 Scores  \\\n",
       "0  [0.92, 0.98, 0.99, 0.99, 1.0]           0.92-1.0   \n",
       "0   [0.95, 0.98, 0.99, 1.0, 1.0]           0.95-1.0   \n",
       "0  [0.92, 0.98, 0.99, 0.99, 1.0]           0.92-1.0   \n",
       "0  [0.92, 0.96, 0.99, 0.99, 1.0]           0.92-1.0   \n",
       "0  [0.95, 0.97, 0.99, 0.99, 1.0]           0.95-1.0   \n",
       "0   [0.96, 0.98, 0.99, 1.0, 1.0]           0.96-1.0   \n",
       "0  [0.93, 0.99, 0.99, 0.99, 1.0]           0.93-1.0   \n",
       "0  [0.92, 0.97, 0.98, 0.99, 1.0]           0.92-1.0   \n",
       "\n",
       "   Std Deviation of F1 Scores  \n",
       "0                    0.032094  \n",
       "0                    0.020736  \n",
       "0                    0.032094  \n",
       "0                    0.032711  \n",
       "0                    0.020000  \n",
       "0                    0.016733  \n",
       "0                    0.028284  \n",
       "0                    0.031145  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_obj = knn\n",
    "model_name = \"K Nearst Neighbour\"\n",
    "process = \"Bag Of Words with NLTK Stemming\"\n",
    "n_splits = 5\n",
    "X = train_ds_features.toarray()\n",
    "y = train_ds.sentiment\n",
    "stratified_K_fold_validation(model_obj, model_name, process, n_splits, X, y)\n",
    "df_model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.fit(train_X.toarray(), train_y)\n",
    "test_ds_predicted = lda.predict( test_X.toarray() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       873\n",
      "           1       0.99      0.99      0.99      1203\n",
      "\n",
      "    accuracy                           0.99      2076\n",
      "   macro avg       0.99      0.99      0.99      2076\n",
      "weighted avg       0.99      0.99      0.99      2076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print( metrics.classification_report( test_y, test_ds_predicted ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object _BaseKFold.split at 0x00000215023B91C8>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Process</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>F1 Scores</th>\n",
       "      <th>Range of F1 Scores</th>\n",
       "      <th>Std Deviation of F1 Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Binomial Naive Bayes Classifier</td>\n",
       "      <td>[0.92, 0.98, 0.99, 0.99, 1.0]</td>\n",
       "      <td>0.92-1.0</td>\n",
       "      <td>0.032094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>[0.95, 0.98, 0.99, 1.0, 1.0]</td>\n",
       "      <td>0.95-1.0</td>\n",
       "      <td>0.020736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Decission Tree</td>\n",
       "      <td>[0.92, 0.98, 0.99, 0.99, 1.0]</td>\n",
       "      <td>0.92-1.0</td>\n",
       "      <td>0.032094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>[0.92, 0.96, 0.99, 0.99, 1.0]</td>\n",
       "      <td>0.92-1.0</td>\n",
       "      <td>0.032711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>XG Boost</td>\n",
       "      <td>[0.95, 0.97, 0.99, 0.99, 1.0]</td>\n",
       "      <td>0.95-1.0</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Stochastic Gradient Descent</td>\n",
       "      <td>[0.96, 0.98, 0.99, 1.0, 1.0]</td>\n",
       "      <td>0.96-1.0</td>\n",
       "      <td>0.016733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Gausian Process</td>\n",
       "      <td>[0.93, 0.99, 0.99, 0.99, 1.0]</td>\n",
       "      <td>0.93-1.0</td>\n",
       "      <td>0.028284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>K Nearst Neighbour</td>\n",
       "      <td>[0.92, 0.97, 0.98, 0.99, 1.0]</td>\n",
       "      <td>0.92-1.0</td>\n",
       "      <td>0.031145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Linear Discriminant Analysis</td>\n",
       "      <td>[0.98, 0.99, 0.99, 0.99, 1.0]</td>\n",
       "      <td>0.98-1.0</td>\n",
       "      <td>0.007071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Process                       Model Name  \\\n",
       "0  Bag Of Words with NLTK Stemming  Binomial Naive Bayes Classifier   \n",
       "0  Bag Of Words with NLTK Stemming              Logistic Regression   \n",
       "0  Bag Of Words with NLTK Stemming                   Decission Tree   \n",
       "0  Bag Of Words with NLTK Stemming                    Random Forest   \n",
       "0  Bag Of Words with NLTK Stemming                         XG Boost   \n",
       "0  Bag Of Words with NLTK Stemming      Stochastic Gradient Descent   \n",
       "0  Bag Of Words with NLTK Stemming                  Gausian Process   \n",
       "0  Bag Of Words with NLTK Stemming               K Nearst Neighbour   \n",
       "0  Bag Of Words with NLTK Stemming     Linear Discriminant Analysis   \n",
       "\n",
       "                       F1 Scores Range of F1 Scores  \\\n",
       "0  [0.92, 0.98, 0.99, 0.99, 1.0]           0.92-1.0   \n",
       "0   [0.95, 0.98, 0.99, 1.0, 1.0]           0.95-1.0   \n",
       "0  [0.92, 0.98, 0.99, 0.99, 1.0]           0.92-1.0   \n",
       "0  [0.92, 0.96, 0.99, 0.99, 1.0]           0.92-1.0   \n",
       "0  [0.95, 0.97, 0.99, 0.99, 1.0]           0.95-1.0   \n",
       "0   [0.96, 0.98, 0.99, 1.0, 1.0]           0.96-1.0   \n",
       "0  [0.93, 0.99, 0.99, 0.99, 1.0]           0.93-1.0   \n",
       "0  [0.92, 0.97, 0.98, 0.99, 1.0]           0.92-1.0   \n",
       "0  [0.98, 0.99, 0.99, 0.99, 1.0]           0.98-1.0   \n",
       "\n",
       "   Std Deviation of F1 Scores  \n",
       "0                    0.032094  \n",
       "0                    0.020736  \n",
       "0                    0.032094  \n",
       "0                    0.032711  \n",
       "0                    0.020000  \n",
       "0                    0.016733  \n",
       "0                    0.028284  \n",
       "0                    0.031145  \n",
       "0                    0.007071  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_obj = lda\n",
    "model_name = \"Linear Discriminant Analysis\"\n",
    "process = \"Bag Of Words with NLTK Stemming\"\n",
    "n_splits = 5\n",
    "X = train_ds_features.toarray()\n",
    "y = train_ds.sentiment\n",
    "stratified_K_fold_validation(model_obj, model_name, process, n_splits, X, y)\n",
    "df_model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.fit(train_X.toarray(), train_y)\n",
    "test_ds_predicted = svm.predict( test_X.toarray() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object _BaseKFold.split at 0x00000215023B9B48>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Process</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>F1 Scores</th>\n",
       "      <th>Range of F1 Scores</th>\n",
       "      <th>Std Deviation of F1 Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Binomial Naive Bayes Classifier</td>\n",
       "      <td>[0.92, 0.98, 0.99, 0.99, 1.0]</td>\n",
       "      <td>0.92-1.0</td>\n",
       "      <td>0.032094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>[0.95, 0.98, 0.99, 1.0, 1.0]</td>\n",
       "      <td>0.95-1.0</td>\n",
       "      <td>0.020736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Decission Tree</td>\n",
       "      <td>[0.92, 0.98, 0.99, 0.99, 1.0]</td>\n",
       "      <td>0.92-1.0</td>\n",
       "      <td>0.032094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>[0.92, 0.96, 0.99, 0.99, 1.0]</td>\n",
       "      <td>0.92-1.0</td>\n",
       "      <td>0.032711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>XG Boost</td>\n",
       "      <td>[0.95, 0.97, 0.99, 0.99, 1.0]</td>\n",
       "      <td>0.95-1.0</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Stochastic Gradient Descent</td>\n",
       "      <td>[0.96, 0.98, 0.99, 1.0, 1.0]</td>\n",
       "      <td>0.96-1.0</td>\n",
       "      <td>0.016733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Gausian Process</td>\n",
       "      <td>[0.93, 0.99, 0.99, 0.99, 1.0]</td>\n",
       "      <td>0.93-1.0</td>\n",
       "      <td>0.028284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>K Nearst Neighbour</td>\n",
       "      <td>[0.92, 0.97, 0.98, 0.99, 1.0]</td>\n",
       "      <td>0.92-1.0</td>\n",
       "      <td>0.031145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Linear Discriminant Analysis</td>\n",
       "      <td>[0.98, 0.99, 0.99, 0.99, 1.0]</td>\n",
       "      <td>0.98-1.0</td>\n",
       "      <td>0.007071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bag Of Words with NLTK Stemming</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>[0.95, 0.97, 0.99, 0.99, 1.0]</td>\n",
       "      <td>0.95-1.0</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Process                       Model Name  \\\n",
       "0  Bag Of Words with NLTK Stemming  Binomial Naive Bayes Classifier   \n",
       "0  Bag Of Words with NLTK Stemming              Logistic Regression   \n",
       "0  Bag Of Words with NLTK Stemming                   Decission Tree   \n",
       "0  Bag Of Words with NLTK Stemming                    Random Forest   \n",
       "0  Bag Of Words with NLTK Stemming                         XG Boost   \n",
       "0  Bag Of Words with NLTK Stemming      Stochastic Gradient Descent   \n",
       "0  Bag Of Words with NLTK Stemming                  Gausian Process   \n",
       "0  Bag Of Words with NLTK Stemming               K Nearst Neighbour   \n",
       "0  Bag Of Words with NLTK Stemming     Linear Discriminant Analysis   \n",
       "0  Bag Of Words with NLTK Stemming           Support Vector Machine   \n",
       "\n",
       "                       F1 Scores Range of F1 Scores  \\\n",
       "0  [0.92, 0.98, 0.99, 0.99, 1.0]           0.92-1.0   \n",
       "0   [0.95, 0.98, 0.99, 1.0, 1.0]           0.95-1.0   \n",
       "0  [0.92, 0.98, 0.99, 0.99, 1.0]           0.92-1.0   \n",
       "0  [0.92, 0.96, 0.99, 0.99, 1.0]           0.92-1.0   \n",
       "0  [0.95, 0.97, 0.99, 0.99, 1.0]           0.95-1.0   \n",
       "0   [0.96, 0.98, 0.99, 1.0, 1.0]           0.96-1.0   \n",
       "0  [0.93, 0.99, 0.99, 0.99, 1.0]           0.93-1.0   \n",
       "0  [0.92, 0.97, 0.98, 0.99, 1.0]           0.92-1.0   \n",
       "0  [0.98, 0.99, 0.99, 0.99, 1.0]           0.98-1.0   \n",
       "0  [0.95, 0.97, 0.99, 0.99, 1.0]           0.95-1.0   \n",
       "\n",
       "   Std Deviation of F1 Scores  \n",
       "0                    0.032094  \n",
       "0                    0.020736  \n",
       "0                    0.032094  \n",
       "0                    0.032711  \n",
       "0                    0.020000  \n",
       "0                    0.016733  \n",
       "0                    0.028284  \n",
       "0                    0.031145  \n",
       "0                    0.007071  \n",
       "0                    0.020000  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_obj = svm\n",
    "model_name = \"Support Vector Machine\"\n",
    "process = \"Bag Of Words with NLTK Stemming\"\n",
    "n_splits = 5\n",
    "X = train_ds_features.toarray()\n",
    "y = train_ds.sentiment\n",
    "stratified_K_fold_validation(model_obj, model_name, process, n_splits, X, y)\n",
    "df_model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_selection.to_csv(\"Model_statistics.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
